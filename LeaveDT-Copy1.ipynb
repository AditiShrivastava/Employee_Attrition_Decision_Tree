{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipdb\n",
    "import pprint\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "train,validate = np.split(data,[int(.8*len(data))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy(df):\n",
    "    Class = \"left\"   #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction+eps)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy_numerical(df):\n",
    "    Class = \"left\"   #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction+eps)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy_attribute(df,attribute):\n",
    "  Class = \"left\"   #To make the code generic, changing target variable class name\n",
    "  target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "  variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "  entropy2 = 0\n",
    "  for variable in variables:\n",
    "      entropy = 0\n",
    "      for target_variable in target_variables:\n",
    "          num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "          den = len(df[attribute][df[attribute]==variable])\n",
    "          fraction = num/(den+eps)\n",
    "          entropy += -fraction*log(fraction+eps)\n",
    "      fraction2 = den/len(df)\n",
    "      entropy2 += -fraction2*entropy\n",
    "  return abs(entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy_attribute_numerical(df,attribute):\n",
    "  Class = \"left\"   #To make the code generic, changing target variable class name\n",
    "  target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "  variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "  entropy2 = 0\n",
    "  for variable in variables:\n",
    "      entropy = 0\n",
    "      for target_variable in target_variables:\n",
    "          num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "          den = len(df[attribute][df[attribute]==variable])\n",
    "          fraction = num/(den+eps)\n",
    "          entropy += -fraction*log(fraction+eps)\n",
    "      fraction2 = den/len(df)\n",
    "      entropy2 += -fraction2*entropy\n",
    "  return abs(entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_attributes = [\"Work_accident\", \"promotion_last_5years\", \"sales\", \"salary\"]\n",
    "numerical_attributes = [\"satisfaction_level\",\"last_evaluation\",\"number_project\",\"average_montly_hours\",\"time_spend_company\"]\n",
    "my_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_winner(df):\n",
    "#     ipdb.set_trace()\n",
    "    for key in categorical_attributes:\n",
    "        if key == \"left\":\n",
    "            continue\n",
    "        my_dict[key] = find_entropy(df) - find_entropy_attribute(df,key)\n",
    "        \n",
    "    \n",
    "    match = max(my_dict, key=my_dict.get)\n",
    "    return match,my_dict[match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_winner_numerical(df):\n",
    "    max = 0\n",
    "    for key in numerical_attributes:\n",
    "        variables = df[key].unique()\n",
    "        \n",
    "        print (variables)\n",
    "        print(\"hehe\")\n",
    "        \n",
    "        \n",
    "        \n",
    "find_winner_numerical(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtable(df, node,value):\n",
    "  print(value)\n",
    "  return df[df[node] == value].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTree(df): \n",
    "    Class = \"left\"   #To make the code generic, changing target variable class name\n",
    "    #Here we build our decision tree\n",
    "    #Get attribute with maximum information gain\n",
    "    node1,gain1 = find_winner(df)\n",
    "    node2,gain2,value = find_winner_numerical(df)\n",
    "    if gain1>gain2:\n",
    "        root = node1\n",
    "        #Get distinct value of that attribute e.g Salary is node and Low,Med and High are values\n",
    "        attValues = df[node1].unique()\n",
    "        #Create an empty dictionary to create tree    \n",
    "        tree={}\n",
    "        tree[node1] = {}\n",
    "        #We make loop to construct a tree by calling this function recursively. \n",
    "        #In this we check if the subset is pure and stops if it is pure. \n",
    "\n",
    "        for loop_val in attValues:\n",
    "        #         ipdb.set_trace()\n",
    "            subtable = get_subtable(df,node1,loop_val)\n",
    "            unique_labels = subtable['left'].unique()                        \n",
    "            if len(unique_labels)==1:   #Checking purity of subset\n",
    "                tree[node1][gain1] = unique_labels[0] \n",
    "            else:        \n",
    "                tree[node1][gain1] = buildTree(subtable) #Calling the function recursively \n",
    "                \n",
    "    else:\n",
    "        tree={}\n",
    "        tree[node2] = {}\n",
    "        root = node2\n",
    "        subtable_left = df[df['node2'] <= value]\n",
    "        unique_labels = subtable_left['left'].unique()\n",
    "        if len(unique_labels)==1:   #Checking purity of subset\n",
    "            tree[node2][gain2] = unique_labels[0] \n",
    "        else:        \n",
    "            tree[node2][gain2] = buildTree(subtable_left) #Calling the function recursively\n",
    "        \n",
    "        subtable_right = df[df['node2'] > value]\n",
    "        unique_labels = subtable_right['left'].unique()\n",
    "        if len(unique_labels)==1:   #Checking purity of subset\n",
    "            tree[node2][gain2] = unique_labels[0] \n",
    "        else:        \n",
    "            tree[node2][gain2] = buildTree(subtable_right) #Calling the function recursively\n",
    "        \n",
    "        \n",
    "        \n",
    "    return tree\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint.pprint(buildTree(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inst,tree):\n",
    "    #This function is used to predict for any input variable \n",
    "    \n",
    "    #Recursively we go through the tree that we built earlier\n",
    "    \n",
    "    for nodes in tree.keys():        \n",
    "        \n",
    "        value = inst[nodes]\n",
    "        tree = tree[nodes][value]\n",
    "        prediction = 0\n",
    "            \n",
    "        if type(tree) is dict:\n",
    "            prediction = predict(inst, tree)\n",
    "        else:\n",
    "            prediction = tree\n",
    "            break;                            \n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildTree(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_TP_FP_TN_FN(tree):\n",
    "    FP=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    for index, row in validate.iterrows():\n",
    "        predicted = predict(row,tree)\n",
    "        actual = row[\"left\"]\n",
    "        if predicted == 0 :\n",
    "            if actual == 0:\n",
    "                TN+=1\n",
    "            if actual == 1:\n",
    "                FN+=1\n",
    "        if predicted == 1:\n",
    "            if actual == 0:\n",
    "                FP+=1\n",
    "            if actual == 1:\n",
    "                TP+=1\n",
    "    return TP,FP,TN,FN\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP,FP,TN,FN = cal_TP_FP_TN_FN(tree)\n",
    "print (TP)\n",
    "print (FP)\n",
    "print (TN)\n",
    "print (FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy():\n",
    "    total = TN+FP+TP+FN\n",
    "    true = TN + TP\n",
    "    accuracy = true / total\n",
    "    print(accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = calc_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision():\n",
    "    positive = TP + FP\n",
    "    precision = TP / positive\n",
    "    print(precision)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = calc_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_recall():\n",
    "    actual_positive = TP + FN\n",
    "    precision = TP / actual_positive\n",
    "    print(precision)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = calc_recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f1score():\n",
    "    recall_inv = 1/recall;\n",
    "    precision_inv = 1/precision\n",
    "    den = recall_inv + precision_inv\n",
    "    f1_score = 2 / den\n",
    "    print(f1_score)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = calc_f1score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
