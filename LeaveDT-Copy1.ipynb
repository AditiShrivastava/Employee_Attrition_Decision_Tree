{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipdb\n",
    "import pprint\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "train,validate = np.split(data,[int(.8*len(data))])\n",
    "numerical_node = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy(df):\n",
    "    Class = \"left\"   #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction+eps)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy_numerical(df):\n",
    "    Class = \"left\"   #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = float(df[Class].value_counts()[value])/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction+eps)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy_attribute(df,attribute):\n",
    "  Class = \"left\"   #To make the code generic, changing target variable class name\n",
    "  target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "  variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "  entropy2 = 0\n",
    "  for variable in variables:\n",
    "      entropy = 0\n",
    "      for target_variable in target_variables:\n",
    "          num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "          den = len(df[attribute][df[attribute]==variable])\n",
    "          fraction = num/(den+eps)\n",
    "          entropy += -fraction*log(fraction+eps)\n",
    "      fraction2 = den/len(df)\n",
    "      entropy2 += -fraction2*entropy\n",
    "  return abs(entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy_attribute_numerical(df,attribute):\n",
    "    Class = \"left\"   #To make the code generic, changing target variable class name\n",
    "    target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "    variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "    node = None\n",
    "    min_entropy = None\n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        entropy2 = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]<=variable][df[Class] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]<=variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*log(fraction+eps)\n",
    "        fraction2 = den/len(df)\n",
    "        entropy2 += -fraction2*entropy\n",
    "    \n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]>variable][df[Class] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]>variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*log(fraction+eps)\n",
    "        fraction2 = den/len(df)\n",
    "        entropy2 += -fraction2*entropy\n",
    "    \n",
    "    if min_entropy == None or min_entropy > abs(entropy2):\n",
    "        min_entropy = abs(entropy2)\n",
    "        node = variable\n",
    "    return min_entropy,node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_attributes = [\"Work_accident\", \"promotion_last_5years\", \"sales\", \"salary\"]\n",
    "numerical_attributes = [\"satisfaction_level\",\"last_evaluation\",\"number_project\",\"average_montly_hours\",\"time_spend_company\"]\n",
    "my_dict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_winner(df):\n",
    "#     ipdb.set_trace()\n",
    "    for key in categorical_attributes:\n",
    "        my_dict[key] = find_entropy(df) - find_entropy_attribute(df,key)   \n",
    "    match = max(my_dict, key=my_dict.get)\n",
    "    return match,my_dict[match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_winner_numerical(df):\n",
    "    entropy_before_split = find_entropy(df) \n",
    "    max_gain = None\n",
    "    max_attribute = None\n",
    "    max_node = None\n",
    "    for key in numerical_attributes:\n",
    "        entropy,temp_node = find_entropy_attribute_numerical(df,key)\n",
    "        if max_gain ==None or max_gain < entropy_before_split - entropy:\n",
    "            max_gain = entropy_before_split - entropy\n",
    "            max_node = temp_node\n",
    "            max_attribute = key\n",
    "        \n",
    "    \n",
    "    return max_attribute,max_gain,max_node      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtable(df, node,value):\n",
    "  #print(value)\n",
    "  return df[df[node] == value].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTree(df): \n",
    "    Class = \"left\"   #To make the code generic, changing target variable class name\n",
    "    #Here we build our decision tree\n",
    "    #Get attribute with maximum information gain\n",
    "    node1,gain1 = find_winner(df)\n",
    "    max_attribute,max_gain,max_node = find_winner_numerical(df)\n",
    "    if gain1 == 0 and max_gain == 0 :\n",
    "        count_0 = len(df[df['left'] == 0])\n",
    "        count_1 = len(df[df['left'] == 1])\n",
    "        \n",
    "        if count_0 > count_1:\n",
    "            max = 0\n",
    "        else:\n",
    "            max = 1\n",
    "        return max\n",
    "    \n",
    "    if gain1>max_gain:\n",
    "        root = node1\n",
    "        #Get distinct value of that attribute e.g Salary is node and Low,Med and High are values\n",
    "        attValues = df[node1].unique()\n",
    "        #Create an empty dictionary to create tree    \n",
    "        tree={}\n",
    "        tree[node1] = {}\n",
    "        #We make loop to construct a tree by calling this function recursively. \n",
    "        #In this we check if the subset is pure and stops if it is pure. \n",
    "\n",
    "        for loop_val in attValues:\n",
    "        #         ipdb.set_trace()\n",
    "            subtable = get_subtable(df,node1,loop_val)\n",
    "            unique_labels = subtable['left'].unique()                        \n",
    "            if len(unique_labels)==1:   #Checking purity of subset\n",
    "                tree[node1][loop_val] = unique_labels[0] \n",
    "            else:        \n",
    "                tree[node1][loop_val] = buildTree(subtable) #Calling the function recursively \n",
    "                \n",
    "    else:\n",
    "        tree={}\n",
    "        tree[max_attribute] = {}\n",
    "        root = max_attribute\n",
    "        subtable_left = df[df[max_attribute] <= max_node].reset_index(drop=True)\n",
    "        unique_labels = subtable_left['left'].unique()\n",
    "        if len(unique_labels)==1:   #Checking purity of subset\n",
    "            tree[max_attribute][max_node] = unique_labels[0] \n",
    "        else:        \n",
    "            tree[max_attribute][max_node] = buildTree(subtable_left) #Calling the function recursively\n",
    "        \n",
    "        subtable_right = df[df[max_attribute] > max_node].reset_index(drop=True)\n",
    "        unique_labels = subtable_right['left'].unique()\n",
    "        if len(unique_labels)==1:   #Checking purity of subset\n",
    "            tree[max_attribute][max_node+0.0001] = unique_labels[0] \n",
    "        else:        \n",
    "            tree[max_attribute][max_node+0.0001] = buildTree(subtable_right) #Calling the function recursively\n",
    "        \n",
    "        \n",
    "        \n",
    "    return tree\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint.pprint(buildTree(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(inst,tree):\n",
    "#     #This function is used to predict for any input variable \n",
    "    \n",
    "#     #Recursively we go through the tree that we built earlier\n",
    "    \n",
    "#     for nodes in tree.keys():        \n",
    "        \n",
    "#         value = inst[nodes]\n",
    "#         tree = tree[nodes][value]\n",
    "#         prediction = 0\n",
    "            \n",
    "#         if type(tree) is dict:\n",
    "#             prediction = predict(inst, tree)\n",
    "#         else:\n",
    "#             prediction = tree\n",
    "#             break;                            \n",
    "        \n",
    "#     return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildTree(train)\n",
    "pprint.pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inst,tree):\n",
    "    global categorical_attributes\n",
    "    global numerical_attributes\n",
    "    #This function is used to predict for any input variable \n",
    "    \n",
    "    #Recursively we go through the tree that we built earlier\n",
    "#     print(tree)\n",
    "    for nodes in tree.keys():        \n",
    "        value = inst[nodes]\n",
    "        if nodes in categorical_attributes:\n",
    "            if value in list((tree[nodes]).keys()):\n",
    "                tree = tree[nodes][value]\n",
    "            else:\n",
    "                zeros = 0\n",
    "                ones = 0\n",
    "                for i in tree[nodes].keys():\n",
    "                    if tree[nodes][i] == 0:\n",
    "                        zeros += 1\n",
    "                    elif tree[nodes][i] == 1:\n",
    "                        ones += 1\n",
    "                if zeros > ones:\n",
    "                    return 0\n",
    "                else:\n",
    "                    return 1\n",
    "                  \n",
    "        elif nodes in numerical_attributes:\n",
    "            first_key = list(tree[nodes].keys())[0]\n",
    "            if value <= first_key :\n",
    "                tree = tree[nodes][first_key]\n",
    "            else:\n",
    "                second_key = list(tree[nodes].keys())[1]\n",
    "                tree = tree[nodes][second_key]\n",
    "        prediction = 0\n",
    "\n",
    "        if type(tree) is dict:\n",
    "            prediction = predict(inst, tree)\n",
    "        else:\n",
    "            prediction = tree\n",
    "            break;\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_TP_FP_TN_FN(tree):\n",
    "    FP=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    for index, row in validate.iterrows():\n",
    "        predicted = predict(row,tree)\n",
    "        actual = row[\"left\"]\n",
    "        if predicted == 0 :\n",
    "            if actual == 0:\n",
    "                TN+=1\n",
    "            if actual == 1:\n",
    "                FN+=1\n",
    "        if predicted == 1:\n",
    "            if actual == 0:\n",
    "                FP+=1\n",
    "            if actual == 1:\n",
    "                TP+=1\n",
    "    return TP,FP,TN,FN\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP,FP,TN,FN = cal_TP_FP_TN_FN(tree)\n",
    "print (TP)\n",
    "print (FP)\n",
    "print (TN)\n",
    "print (FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy():\n",
    "    total = TN+FP+TP+FN\n",
    "    true = TN + TP\n",
    "    accuracy = true / total\n",
    "    print(accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = calc_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision():\n",
    "    positive = TP + FP\n",
    "    precision = TP / positive\n",
    "    print(precision)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = calc_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_recall():\n",
    "    actual_positive = TP + FN\n",
    "    precision = TP / actual_positive\n",
    "    print(precision)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = calc_recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f1score():\n",
    "    recall_inv = 1/recall;\n",
    "    precision_inv = 1/precision\n",
    "    den = recall_inv + precision_inv\n",
    "    f1_score = 2 / den\n",
    "    print(f1_score)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = calc_f1score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
